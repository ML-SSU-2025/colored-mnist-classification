{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4361cff",
   "metadata": {},
   "source": [
    "# PCA 처리에 맞는 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f84941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 02_train_classical_ml.ipynb\n",
    "#\n",
    "# Train classical ML models (KNN, SVM, Decision Tree,\n",
    "# Random Forest, XGBoost) on Colored MNIST.\n",
    "#\n",
    "# - Uses preprocessed features from 01_preprocessing_colored_mnist.ipynb\n",
    "# - Supports 3 tasks:\n",
    "#     1) Digit classification (0-9)\n",
    "#     2) Foreground color classification (7 classes, ROYGBIV)\n",
    "#     3) Background color classification (7 classes, ROYGBIV)\n",
    "# ============================================================\n",
    "\n",
    "import os  # path handling\n",
    "import numpy as np  # numerical operations\n",
    "import matplotlib.pyplot as plt  # visualization\n",
    "import seaborn as sns  # nicer plots\n",
    "\n",
    "from sklearn.metrics import (  # evaluation metrics\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV  # hyperparameter tuning\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier  # KNN model\n",
    "from sklearn.svm import SVC  # SVM model\n",
    "from sklearn.tree import DecisionTreeClassifier  # Decision Tree model\n",
    "from sklearn.ensemble import RandomForestClassifier  # Random Forest model\n",
    "\n",
    "\n",
    "\n",
    "# Matplotlib style (English only)\n",
    "plt.rcParams[\"font.family\"] = \"DejaVu Sans\"  # default font\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False  # minus sign\n",
    "sns.set(style=\"whitegrid\")  # seaborn style\n",
    "\n",
    "RANDOM_STATE = 42  # global random seed for reproducibility\n",
    "\n",
    "print(\"[OK] Libraries imported.\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Resolve BASE_DIR and processed npz path\n",
    "# ------------------------------------------------------------\n",
    "cwd = os.getcwd()  # current working directory\n",
    "\n",
    "# If current folder is 'notebooks', use its parent as repo root\n",
    "if os.path.basename(cwd) == \"notebooks\":  # check folder name\n",
    "    BASE_DIR = os.path.dirname(cwd)  # go one level up\n",
    "else:\n",
    "    BASE_DIR = cwd  # otherwise use current directory as root\n",
    "\n",
    "PROCESSED_PATH = os.path.join(\n",
    "    BASE_DIR, BASE_DIR, \"drive\", \"MyDrive\", \"2025-ML\", \"data\", \"processed\", \"deskewed_pca_mnist.npz\"\n",
    ")  # path to preprocessed npz\n",
    "\n",
    "print(f\"[INFO] BASE_DIR       : {BASE_DIR}\")\n",
    "print(f\"[INFO] PROCESSED_PATH : {PROCESSED_PATH}\")\n",
    "\n",
    "if not os.path.exists(PROCESSED_PATH):  # check if file exists\n",
    "    raise FileNotFoundError(\n",
    "        f\"[ERROR] Processed file not found at {PROCESSED_PATH}.\\n\"\n",
    "        f\"Please run 01_preprocessing_colored_mnist.ipynb first.\"\n",
    "    )\n",
    "\n",
    "data = np.load(PROCESSED_PATH)  # load npz file into memory\n",
    "print(\"[OK] Loaded npz keys:\", list(data.keys()))\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Extract features (scaled + raw)\n",
    "#   - X_*     : standardized features (mean=0, std=1) for classical ML\n",
    "#   - X_*_raw : flattened RGB in [0,1] (for PCA or other future use)\n",
    "# ------------------------------------------------------------\n",
    "X_train = data[\"X_train\"].astype(np.float32)  # scaled train features\n",
    "X_val   = data[\"X_val\"].astype(np.float32)    # scaled val features\n",
    "X_test  = data[\"X_test\"].astype(np.float32)   # scaled test features\n",
    "\n",
    "X_train_raw = data[\"X_train_raw\"].astype(np.float32)  # raw train features (0-1)\n",
    "X_val_raw   = data[\"X_val_raw\"].astype(np.float32)    # raw val features\n",
    "X_test_raw  = data[\"X_test_raw\"].astype(np.float32)   # raw test features\n",
    "\n",
    "print(\"[INFO] Feature shapes (scaled):\")\n",
    "print(\"  X_train:\", X_train.shape)\n",
    "print(\"  X_val  :\", X_val.shape)\n",
    "print(\"  X_test :\", X_test.shape)\n",
    "\n",
    "print(\"[INFO] Raw features are loaded as well, reserved for future use (e.g., PCA).\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Select task: \"digit\", \"fg\", or \"bg\"\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "TASK = \"digit\"  # change to \"fg\" or \"bg\" depending on experiment\n",
    "\n",
    "if TASK == \"digit\":\n",
    "    y_train = data[\"y_train\"]  # digit labels for train\n",
    "    y_val   = data[\"y_val\"]    # digit labels for val\n",
    "    y_test  = data[\"y_test\"]   # digit labels for test\n",
    "    class_names = [str(i) for i in range(10)]  # class names \"0\"~\"9\"\n",
    "\n",
    "    print(\"[TASK] Digit classification (0-9).\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"[INFO] Label shapes:\")\n",
    "print(\"  y_train:\", y_train.shape)\n",
    "print(\"  y_val  :\", y_val.shape)\n",
    "print(\"  y_test :\", y_test.shape)\n",
    "print(\"  num_classes:\", len(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ccd8346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# [Cell 2] Utility function to evaluate a classifier\n",
    "#   - Trains the model on (X_train, y_train)\n",
    "#   - Evaluates on both val and test sets\n",
    "#   - Prints accuracy / precision / recall / F1\n",
    "#   - Shows confusion matrix for each split\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def evaluate_classifier(model,  # sklearn/xgboost-like estimator\n",
    "                        model_name: str,\n",
    "                        X_train, y_train,\n",
    "                        X_val, y_val,\n",
    "                        X_test, y_test,\n",
    "                        class_names):\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"[MODEL] {model_name}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # --------- Train ---------\n",
    "    model.fit(X_train, y_train)  # fit classifier on training data\n",
    "    print(\"[OK] Training finished.\")\n",
    "\n",
    "    # --------- Validation evaluation ---------\n",
    "    y_val_pred = model.predict(X_val)  # predictions for validation set\n",
    "    acc_val = accuracy_score(y_val, y_val_pred)  # validation accuracy\n",
    "    pr_val, rc_val, f1_val, _ = precision_recall_fscore_support(\n",
    "        y_val, y_val_pred, average=\"weighted\", zero_division=0\n",
    "    )  # weighted precision/recall/F1\n",
    "\n",
    "    print(\"\\n[Val] Metrics:\")\n",
    "    print(f\"  Accuracy : {acc_val:.4f}\")\n",
    "    print(f\"  Precision: {pr_val:.4f}\")\n",
    "    print(f\"  Recall   : {rc_val:.4f}\")\n",
    "    print(f\"  F1-score : {f1_val:.4f}\")\n",
    "    print(\"\\n[Val] Classification report:\")\n",
    "    print(classification_report(y_val, y_val_pred, target_names=class_names, zero_division=0))\n",
    "\n",
    "    cm_val = confusion_matrix(y_val, y_val_pred)  # confusion matrix for validation\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm_val, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f\"{model_name} - Val Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # --------- Test evaluation ---------\n",
    "    y_test_pred = model.predict(X_test)  # predictions for test set\n",
    "    acc_test = accuracy_score(y_test, y_test_pred)  # test accuracy\n",
    "    pr_test, rc_test, f1_test, _ = precision_recall_fscore_support(\n",
    "        y_test, y_test_pred, average=\"weighted\", zero_division=0\n",
    "    )\n",
    "\n",
    "    print(\"\\n[Test] Metrics:\")\n",
    "    print(f\"  Accuracy : {acc_test:.4f}\")\n",
    "    print(f\"  Precision: {pr_test:.4f}\")\n",
    "    print(f\"  Recall   : {rc_test:.4f}\")\n",
    "    print(f\"  F1-score : {f1_test:.4f}\")\n",
    "    print(\"\\n[Test] Classification report:\")\n",
    "    print(classification_report(y_test, y_test_pred, target_names=class_names, zero_division=0))\n",
    "\n",
    "    cm_test = confusion_matrix(y_test, y_test_pred)  # confusion matrix for test\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm_test, annot=True, fmt=\"d\", cmap=\"Greens\",\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f\"{model_name} - Test Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Return dictionary for later summary if needed\n",
    "    return {\n",
    "        \"model\": model,\n",
    "        \"acc_val\": acc_val,\n",
    "        \"f1_val\": f1_val,\n",
    "        \"acc_test\": acc_test,\n",
    "        \"f1_test\": f1_test,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1c33d75",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KNeighborsClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ------------------------------------------------------------\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# [Cell 3] KNN with hyperparameter tuning (GridSearchCV)\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#   - Uses scaled features X_train / X_val / X_test\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      6\u001b[39m \n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Define base KNN classifier\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m knn_base = \u001b[43mKNeighborsClassifier\u001b[49m(\n\u001b[32m     10\u001b[39m     n_neighbors=\u001b[32m3\u001b[39m,\n\u001b[32m     11\u001b[39m     weights=\u001b[33m'\u001b[39m\u001b[33muniform\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     12\u001b[39m     p=\u001b[32m1\u001b[39m,\n\u001b[32m     13\u001b[39m     metric=\u001b[33m'\u001b[39m\u001b[33mminkowski\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     14\u001b[39m     n_jobs=-\u001b[32m1\u001b[39m\n\u001b[32m     15\u001b[39m )\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# default KNN classifier\u001b[39;00m\n\u001b[32m     18\u001b[39m \n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Define hyperparameter search space for KNN\u001b[39;00m\n\u001b[32m     20\u001b[39m param_grid_knn = {\n\u001b[32m     21\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mn_neighbors\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[32m3\u001b[39m, \u001b[32m5\u001b[39m, \u001b[32m7\u001b[39m, \u001b[32m9\u001b[39m],         \u001b[38;5;66;03m# number of neighbors\u001b[39;00m\n\u001b[32m     22\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mweights\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33muniform\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdistance\u001b[39m\u001b[33m\"\u001b[39m],  \u001b[38;5;66;03m# uniform weights vs distance weights\u001b[39;00m\n\u001b[32m     23\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mp\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m],                         \u001b[38;5;66;03m# 1: Manhattan, 2: Euclidean\u001b[39;00m\n\u001b[32m     24\u001b[39m }\n",
      "\u001b[31mNameError\u001b[39m: name 'KNeighborsClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# [Cell 3] KNN with hyperparameter tuning (GridSearchCV)\n",
    "#   - Uses scaled features X_train / X_val / X_test\n",
    "#   - Parameter search over k, weights, and distance metric\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Define base KNN classifier\n",
    "\n",
    "knn_base = KNeighborsClassifier(\n",
    "    n_neighbors=3,\n",
    "    weights='uniform',\n",
    "    p=1,\n",
    "    metric='minkowski',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# default KNN classifier\n",
    "\n",
    "# Define hyperparameter search space for KNN\n",
    "param_grid_knn = {\n",
    "    \"n_neighbors\": [3, 5, 7, 9],         # number of neighbors\n",
    "    \"weights\": [\"uniform\", \"distance\"],  # uniform weights vs distance weights\n",
    "    \"p\": [1, 2],                         # 1: Manhattan, 2: Euclidean\n",
    "}\n",
    "\n",
    "# GridSearchCV configuration\n",
    "knn_grid = GridSearchCV(\n",
    "    estimator=knn_base,     # base KNN model\n",
    "    param_grid=param_grid_knn,  # parameter search space\n",
    "    scoring=\"accuracy\",     # optimization metric (can change to 'f1_weighted')\n",
    "    cv=3,                   # 3-fold cross-validation on training set\n",
    "    n_jobs=-1,              # use all available CPU cores\n",
    "    verbose=2,              # print progress\n",
    ")\n",
    "\n",
    "print(\"[KNN] Starting hyperparameter search...\")\n",
    "knn_grid.fit(X_train, y_train)  # fit GridSearchCV on training data\n",
    "\n",
    "\n",
    "print(\"\\n[KNN] Best parameters:\", knn_grid.best_params_)\n",
    "print(\"[KNN] Best CV accuracy:\", f\"{knn_grid.best_score_:.4f}\")\n",
    "\n",
    "# Extract best model from grid search\n",
    "knn_best = knn_grid.best_estimator_  # best KNN model according to CV\n",
    "\n",
    "# Evaluate best KNN model using common evaluation function\n",
    "results_knn = evaluate_classifier(\n",
    "    model=knn_best,\n",
    "    model_name=\"KNN\",\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    class_names=class_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a69299",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
