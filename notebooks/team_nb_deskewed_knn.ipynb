{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27b85bef",
   "metadata": {},
   "source": [
    "# Deskewed_only 전처리에 맞는 KNN 코드입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa486fab",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5cbc103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Libraries imported.\n",
      "[INFO] BASE_DIR       : c:\\src\\colored-mnist-classification\n",
      "[INFO] PROCESSED_PATH : c:\\src\\colored-mnist-classification\\data\\processed\\deskewed_mnist.npz\n",
      "[OK] Loaded npz keys: ['X_train', 'X_val', 'X_test', 'y_train', 'y_val', 'y_test', 'X_train_raw', 'X_val_raw', 'X_test_raw']\n",
      "[INFO] Feature shapes (scaled):\n",
      "  X_train: (48000, 784)\n",
      "  X_val  : (6000, 784)\n",
      "  X_test : (6000, 784)\n",
      "[INFO] Raw features are loaded as well, reserved for future use (e.g., PCA).\n",
      "[TASK] Digit classification (0-9).\n",
      "[INFO] Label shapes:\n",
      "  y_train: (48000,)\n",
      "  y_val  : (6000,)\n",
      "  y_test : (6000,)\n",
      "  num_classes: 10\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 02_train_classical_ml.ipynb\n",
    "#\n",
    "# Train classical ML models (KNN, SVM, Decision Tree,\n",
    "# Random Forest, XGBoost) on Colored MNIST.\n",
    "#\n",
    "# - Uses preprocessed features from 01_preprocessing_colored_mnist.ipynb\n",
    "# - Supports 3 tasks:\n",
    "#     1) Digit classification (0-9)\n",
    "#     2) Foreground color classification (7 classes, ROYGBIV)\n",
    "#     3) Background color classification (7 classes, ROYGBIV)\n",
    "# ============================================================\n",
    "\n",
    "import os  # path handling\n",
    "import numpy as np  # numerical operations\n",
    "import matplotlib.pyplot as plt  # visualization\n",
    "import seaborn as sns  # nicer plots\n",
    "\n",
    "from sklearn.metrics import (  # evaluation metrics\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV  # hyperparameter tuning\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier  # KNN model\n",
    "from sklearn.svm import SVC  # SVM model\n",
    "from sklearn.tree import DecisionTreeClassifier  # Decision Tree model\n",
    "from sklearn.ensemble import RandomForestClassifier  # Random Forest model\n",
    "\n",
    "\n",
    "\n",
    "# Matplotlib style (English only)\n",
    "plt.rcParams[\"font.family\"] = \"DejaVu Sans\"  # default font\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False  # minus sign\n",
    "sns.set(style=\"whitegrid\")  # seaborn style\n",
    "\n",
    "RANDOM_STATE = 42  # global random seed for reproducibility\n",
    "\n",
    "print(\"[OK] Libraries imported.\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Resolve BASE_DIR and processed npz path\n",
    "# ------------------------------------------------------------\n",
    "cwd = os.getcwd()  # current working directory\n",
    "\n",
    "# If current folder is 'notebooks', use its parent as repo root\n",
    "if os.path.basename(cwd) == \"notebooks\":  # check folder name\n",
    "    BASE_DIR = os.path.dirname(cwd)  # go one level up\n",
    "else:\n",
    "    BASE_DIR = cwd  # otherwise use current directory as root\n",
    "\n",
    "PROCESSED_PATH = os.path.join(\n",
    "    BASE_DIR, BASE_DIR, \"data\", \"processed\", \"deskewed_mnist.npz\"\n",
    ")  # path to preprocessed npz\n",
    "\n",
    "print(f\"[INFO] BASE_DIR       : {BASE_DIR}\")\n",
    "print(f\"[INFO] PROCESSED_PATH : {PROCESSED_PATH}\")\n",
    "\n",
    "if not os.path.exists(PROCESSED_PATH):  # check if file exists\n",
    "    raise FileNotFoundError(\n",
    "        f\"[ERROR] Processed file not found at {PROCESSED_PATH}.\\n\"\n",
    "        f\"Please run 01_preprocessing_colored_mnist.ipynb first.\"\n",
    "    )\n",
    "\n",
    "data = np.load(PROCESSED_PATH)  # load npz file into memory\n",
    "print(\"[OK] Loaded npz keys:\", list(data.keys()))\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Extract features (scaled + raw)\n",
    "#   - X_*     : standardized features (mean=0, std=1) for classical ML\n",
    "#   - X_*_raw : flattened RGB in [0,1] (for PCA or other future use)\n",
    "# ------------------------------------------------------------\n",
    "X_train = data[\"X_train\"].astype(np.float32)  # scaled train features\n",
    "X_val   = data[\"X_val\"].astype(np.float32)    # scaled val features\n",
    "X_test  = data[\"X_test\"].astype(np.float32)   # scaled test features\n",
    "\n",
    "X_train_raw = data[\"X_train_raw\"].astype(np.float32)  # raw train features (0-1)\n",
    "X_val_raw   = data[\"X_val_raw\"].astype(np.float32)    # raw val features\n",
    "X_test_raw  = data[\"X_test_raw\"].astype(np.float32)   # raw test features\n",
    "\n",
    "print(\"[INFO] Feature shapes (scaled):\")\n",
    "print(\"  X_train:\", X_train.shape)\n",
    "print(\"  X_val  :\", X_val.shape)\n",
    "print(\"  X_test :\", X_test.shape)\n",
    "\n",
    "print(\"[INFO] Raw features are loaded as well, reserved for future use (e.g., PCA).\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Select task: \"digit\", \"fg\", or \"bg\"\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "TASK = \"digit\"  # change to \"fg\" or \"bg\" depending on experiment\n",
    "\n",
    "if TASK == \"digit\":\n",
    "    y_train = data[\"y_train\"]  # digit labels for train\n",
    "    y_val   = data[\"y_val\"]    # digit labels for val\n",
    "    y_test  = data[\"y_test\"]   # digit labels for test\n",
    "    class_names = [str(i) for i in range(10)]  # class names \"0\"~\"9\"\n",
    "    \n",
    "    print(\"[TASK] Digit classification (0-9).\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"[INFO] Label shapes:\")\n",
    "print(\"  y_train:\", y_train.shape)\n",
    "print(\"  y_val  :\", y_val.shape)\n",
    "print(\"  y_test :\", y_test.shape)\n",
    "print(\"  num_classes:\", len(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55defebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# [Cell 2] Utility function to evaluate a classifier\n",
    "#   - Trains the model on (X_train, y_train)\n",
    "#   - Evaluates on both val and test sets\n",
    "#   - Prints accuracy / precision / recall / F1\n",
    "#   - Shows confusion matrix for each split\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def evaluate_classifier(model,  # sklearn/xgboost-like estimator\n",
    "                        model_name: str,\n",
    "                        X_train, y_train,\n",
    "                        X_val, y_val,\n",
    "                        X_test, y_test,\n",
    "                        class_names):\n",
    "    \"\"\"Train and evaluate a classifier on val and test sets.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : estimator\n",
    "        Classifier implementing fit/predict.\n",
    "    model_name : str\n",
    "        Human-readable model name for printing.\n",
    "    X_train, y_train : array-like\n",
    "        Training features and labels.\n",
    "    X_val, y_val : array-like\n",
    "        Validation features and labels.\n",
    "    X_test, y_test : array-like\n",
    "        Test features and labels.\n",
    "    class_names : list of str\n",
    "        Names of classes, used for reports and confusion matrices.\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"[MODEL] {model_name}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # --------- Train ---------\n",
    "    model.fit(X_train, y_train)  # fit classifier on training data\n",
    "    print(\"[OK] Training finished.\")\n",
    "\n",
    "    # --------- Validation evaluation ---------\n",
    "    y_val_pred = model.predict(X_val)  # predictions for validation set\n",
    "    acc_val = accuracy_score(y_val, y_val_pred)  # validation accuracy\n",
    "    pr_val, rc_val, f1_val, _ = precision_recall_fscore_support(\n",
    "        y_val, y_val_pred, average=\"weighted\", zero_division=0\n",
    "    )  # weighted precision/recall/F1\n",
    "\n",
    "    print(\"\\n[Val] Metrics:\")\n",
    "    print(f\"  Accuracy : {acc_val:.4f}\")\n",
    "    print(f\"  Precision: {pr_val:.4f}\")\n",
    "    print(f\"  Recall   : {rc_val:.4f}\")\n",
    "    print(f\"  F1-score : {f1_val:.4f}\")\n",
    "    print(\"\\n[Val] Classification report:\")\n",
    "    print(classification_report(y_val, y_val_pred, target_names=class_names, zero_division=0))\n",
    "\n",
    "    cm_val = confusion_matrix(y_val, y_val_pred)  # confusion matrix for validation\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm_val, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f\"{model_name} - Val Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # --------- Test evaluation ---------\n",
    "    y_test_pred = model.predict(X_test)  # predictions for test set\n",
    "    acc_test = accuracy_score(y_test, y_test_pred)  # test accuracy\n",
    "    pr_test, rc_test, f1_test, _ = precision_recall_fscore_support(\n",
    "        y_test, y_test_pred, average=\"weighted\", zero_division=0\n",
    "    )\n",
    "\n",
    "    print(\"\\n[Test] Metrics:\")\n",
    "    print(f\"  Accuracy : {acc_test:.4f}\")\n",
    "    print(f\"  Precision: {pr_test:.4f}\")\n",
    "    print(f\"  Recall   : {rc_test:.4f}\")\n",
    "    print(f\"  F1-score : {f1_test:.4f}\")\n",
    "    print(\"\\n[Test] Classification report:\")\n",
    "    print(classification_report(y_test, y_test_pred, target_names=class_names, zero_division=0))\n",
    "\n",
    "    cm_test = confusion_matrix(y_test, y_test_pred)  # confusion matrix for test\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm_test, annot=True, fmt=\"d\", cmap=\"Greens\",\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f\"{model_name} - Test Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Return dictionary for later summary if needed\n",
    "    return {\n",
    "        \"model\": model,\n",
    "        \"acc_val\": acc_val,\n",
    "        \"f1_val\": f1_val,\n",
    "        \"acc_test\": acc_test,\n",
    "        \"f1_test\": f1_test,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23d0d06",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (824271066.py, line 28)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mn_neighbors=5\u001b[39m\n                ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# [Cell 3] KNN with hyperparameter tuning (GridSearchCV)\n",
    "#   - Uses scaled features X_train / X_val / X_test\n",
    "#   - Parameter search over k, weights, and distance metric\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "'''import threading\n",
    "import psutil\n",
    "import time\n",
    "\n",
    "stop_heartbeat = False\n",
    "\n",
    "def heartbeat():\n",
    "    start_time = time.time()\n",
    "    while not stop_heartbeat:\n",
    "        cpu = psutil.cpu_percent(interval=1)\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"[Heartbeat] CPU: {cpu:.1f}% | Elapsed: {elapsed/60:.2f} min\")\n",
    "        time.sleep(1)\n",
    "\n",
    "\n",
    "hb_thread = threading.Thread(target=heartbeat)\n",
    "hb_thread.start()'''\n",
    "\n",
    "# Define base KNN classifier\n",
    "\n",
    "knn_base = KNeighborsClassifier(\n",
    "    n_neighbors=3,\n",
    "    weights='distance',\n",
    "    p=1,\n",
    "    metric='minkowski',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# default KNN classifier\n",
    "\n",
    "# Define hyperparameter search space for KNN\n",
    "'''param_grid_knn = {\n",
    "    \"n_neighbors\": [3, 5, 7, 9],         # number of neighbors\n",
    "    \"weights\": [\"uniform\", \"distance\"],  # uniform weights vs distance weights\n",
    "    \"p\": [1, 2],                         # 1: Manhattan, 2: Euclidean\n",
    "}'''\n",
    "\n",
    "# GridSearchCV configuration\n",
    "'''knn_grid = GridSearchCV(\n",
    "    estimator=knn_base,     # base KNN model\n",
    "    param_grid=param_grid_knn,  # parameter search space\n",
    "    scoring=\"accuracy\",     # optimization metric (can change to 'f1_weighted')\n",
    "    cv=3,                   # 3-fold cross-validation on training set\n",
    "    n_jobs=-1,              # use all available CPU cores\n",
    "    verbose=2,              # print progress\n",
    ")'''\n",
    "\n",
    "print(\"[KNN] Starting hyperparameter search...\")\n",
    "'''knn_grid.fit(X_train, y_train)  # fit GridSearchCV on training data'''\n",
    "\n",
    "stop_heartbeat = True\n",
    "\n",
    "\n",
    "'''print(\"\\n[KNN] Best parameters:\", knn_grid.best_params_)\n",
    "print(\"[KNN] Best CV accuracy:\", f\"{knn_grid.best_score_:.4f}\")'''\n",
    "\n",
    "# Extract best model from grid search\n",
    "'''knn_best = knn_grid.best_estimator_  # best KNN model according to CV'''\n",
    "\n",
    "# Evaluate best KNN model using common evaluation function\n",
    "results_knn = evaluate_classifier(\n",
    "    model=knn_base,\n",
    "    model_name=\"KNN\",\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    class_names=class_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fedeb54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
