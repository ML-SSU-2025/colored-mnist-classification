{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 03_baseline_train\n",
        "- Author: \n",
        "- Date: 2025-10-23\n",
        "- Goal: Baseline CNN 학습 및 로깅\n",
        "- Input: \n",
        "- Output: \n",
        "- Metrics: acc@val, loss@train\n",
        "- Repro: seed=42, device=auto, config=../configs/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a91d3fe9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[OK] Imports ready.\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# 03_analysis_report.ipynb\n",
        "#\n",
        "# 목적:\n",
        "#   - 02_train_classical_ml.ipynb 결과를 정리/분석하여\n",
        "#     보고서와 발표 자료에 바로 사용할 수 있는 형태로 가공한다.\n",
        "#\n",
        "# 주요 기능:\n",
        "#   1) metrics CSV 로드 및 Task별 모델 성능 비교 표 생성\n",
        "#   2) 각 Task에서 Best Model 선택 (macro F1 기준)\n",
        "#   3) Confusion Matrix / Feature Importance 결과 해석 가이드 작성\n",
        "#   4) \"결과 → 원인 → 의미 → 결론\" 구조의 분석 문단 자동 생성\n",
        "#\n",
        "# 전제:\n",
        "#   - 01, 02 노트북이 먼저 정상적으로 실행되어야 함\n",
        "#   - results/metrics/, results/figures/ 이미 존재\n",
        "# ============================================================\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# [Cell 1] 기본 설정 및 라이브러리 임포트\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "import os  # 경로 제어\n",
        "import numpy as np  # 수치 계산\n",
        "import pandas as pd  # 테이블 데이터 로딩/처리\n",
        "import matplotlib.pyplot as plt  # 시각화\n",
        "import seaborn as sns  # heatmap 및 스타일\n",
        "\n",
        "# 시각화 스타일: 보고서용으로 깔끔하게\n",
        "plt.style.use(\"default\")\n",
        "plt.rcParams[\"font.family\"] = \"DejaVu Sans\"  # 영어 기준 폰트\n",
        "plt.rcParams[\"axes.unicode_minus\"] = False\n",
        "\n",
        "print(\"[OK] Imports ready.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a7b8ed0e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] BASE_DIR   : /Users/jaehun_jung/colored-mnist-classification\n",
            "[INFO] METRICS_DIR: /Users/jaehun_jung/colored-mnist-classification/results/metrics\n",
            "[INFO] FIGURES_DIR: /Users/jaehun_jung/colored-mnist-classification/results/figures\n"
          ]
        }
      ],
      "source": [
        "# ------------------------------------------------------------\n",
        "# [Cell 2] BASE_DIR 및 경로 설정\n",
        "#   - 02와 동일한 방식: notebooks/에서 실행해도 동작하도록 처리\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "cwd = os.getcwd()\n",
        "\n",
        "if os.path.basename(cwd) == \"notebooks\":\n",
        "    BASE_DIR = os.path.dirname(cwd)\n",
        "else:\n",
        "    BASE_DIR = cwd\n",
        "\n",
        "METRICS_DIR = os.path.join(BASE_DIR, \"results\", \"metrics\")\n",
        "FIGURES_DIR = os.path.join(BASE_DIR, \"results\", \"figures\")\n",
        "\n",
        "summary_path = os.path.join(METRICS_DIR, \"classical_ml_summary.csv\")\n",
        "\n",
        "print(\"[INFO] BASE_DIR   :\", BASE_DIR)\n",
        "print(\"[INFO] METRICS_DIR:\", METRICS_DIR)\n",
        "print(\"[INFO] FIGURES_DIR:\", FIGURES_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "66f61230",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[OK] Loaded metrics summary.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>task</th>\n",
              "      <th>model</th>\n",
              "      <th>use_raw_features</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision_macro</th>\n",
              "      <th>recall_macro</th>\n",
              "      <th>f1_macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bg_color</td>\n",
              "      <td>XGBoost</td>\n",
              "      <td>True</td>\n",
              "      <td>0.990819</td>\n",
              "      <td>0.990828</td>\n",
              "      <td>0.990871</td>\n",
              "      <td>0.990845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bg_color</td>\n",
              "      <td>RandomForest</td>\n",
              "      <td>True</td>\n",
              "      <td>0.967211</td>\n",
              "      <td>0.967222</td>\n",
              "      <td>0.967304</td>\n",
              "      <td>0.967251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bg_color</td>\n",
              "      <td>KNN</td>\n",
              "      <td>False</td>\n",
              "      <td>0.963753</td>\n",
              "      <td>0.963991</td>\n",
              "      <td>0.963818</td>\n",
              "      <td>0.963836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bg_color</td>\n",
              "      <td>DecisionTree</td>\n",
              "      <td>True</td>\n",
              "      <td>0.946763</td>\n",
              "      <td>0.946833</td>\n",
              "      <td>0.946994</td>\n",
              "      <td>0.946743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>digit</td>\n",
              "      <td>XGBoost</td>\n",
              "      <td>True</td>\n",
              "      <td>0.936807</td>\n",
              "      <td>0.936703</td>\n",
              "      <td>0.936320</td>\n",
              "      <td>0.936405</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       task         model  use_raw_features  accuracy  precision_macro  \\\n",
              "0  bg_color       XGBoost              True  0.990819         0.990828   \n",
              "1  bg_color  RandomForest              True  0.967211         0.967222   \n",
              "2  bg_color           KNN             False  0.963753         0.963991   \n",
              "3  bg_color  DecisionTree              True  0.946763         0.946833   \n",
              "4     digit       XGBoost              True  0.936807         0.936703   \n",
              "\n",
              "   recall_macro  f1_macro  \n",
              "0      0.990871  0.990845  \n",
              "1      0.967304  0.967251  \n",
              "2      0.963818  0.963836  \n",
              "3      0.946994  0.946743  \n",
              "4      0.936320  0.936405  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ------------------------------------------------------------\n",
        "# [Cell 3] metrics 파일 로드 검증\n",
        "#   - 02 노트북이 제대로 실행되었는지 확인하는 단계\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "if not os.path.exists(summary_path):\n",
        "    raise FileNotFoundError(\n",
        "        f\"[ERROR] {summary_path} not found.\\n\"\n",
        "        \"Please run 02_train_classical_ml.ipynb first.\"\n",
        "    )\n",
        "\n",
        "summary_df = pd.read_csv(summary_path)\n",
        "\n",
        "# 기대 컬럼 구조 체크\n",
        "expected_cols = {\n",
        "    \"task\",\n",
        "    \"model\",\n",
        "    \"accuracy\",\n",
        "    \"precision_macro\",\n",
        "    \"recall_macro\",\n",
        "    \"f1_macro\",\n",
        "}\n",
        "missing = expected_cols - set(summary_df.columns)\n",
        "if missing:\n",
        "    raise ValueError(f\"[ERROR] Missing columns in summary CSV: {missing}\")\n",
        "\n",
        "print(\"[OK] Loaded metrics summary.\")\n",
        "display(summary_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6d4967c6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== Performance table for task: digit =====\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision_macro</th>\n",
              "      <th>recall_macro</th>\n",
              "      <th>f1_macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.9368</td>\n",
              "      <td>0.9367</td>\n",
              "      <td>0.9363</td>\n",
              "      <td>0.9364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>RandomForest</td>\n",
              "      <td>0.9051</td>\n",
              "      <td>0.9052</td>\n",
              "      <td>0.9039</td>\n",
              "      <td>0.9041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>KNN</td>\n",
              "      <td>0.8219</td>\n",
              "      <td>0.8442</td>\n",
              "      <td>0.8191</td>\n",
              "      <td>0.8241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>DecisionTree</td>\n",
              "      <td>0.5357</td>\n",
              "      <td>0.5921</td>\n",
              "      <td>0.5319</td>\n",
              "      <td>0.5414</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          model  accuracy  precision_macro  recall_macro  f1_macro\n",
              "4       XGBoost    0.9368           0.9367        0.9363    0.9364\n",
              "5  RandomForest    0.9051           0.9052        0.9039    0.9041\n",
              "6           KNN    0.8219           0.8442        0.8191    0.8241\n",
              "7  DecisionTree    0.5357           0.5921        0.5319    0.5414"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== Performance table for task: fg_color =====\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision_macro</th>\n",
              "      <th>recall_macro</th>\n",
              "      <th>f1_macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.9922</td>\n",
              "      <td>0.9921</td>\n",
              "      <td>0.9922</td>\n",
              "      <td>0.9922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>RandomForest</td>\n",
              "      <td>0.9811</td>\n",
              "      <td>0.9810</td>\n",
              "      <td>0.9811</td>\n",
              "      <td>0.9811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>DecisionTree</td>\n",
              "      <td>0.9533</td>\n",
              "      <td>0.9534</td>\n",
              "      <td>0.9532</td>\n",
              "      <td>0.9532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>KNN</td>\n",
              "      <td>0.8042</td>\n",
              "      <td>0.8575</td>\n",
              "      <td>0.8057</td>\n",
              "      <td>0.8079</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           model  accuracy  precision_macro  recall_macro  f1_macro\n",
              "8        XGBoost    0.9922           0.9921        0.9922    0.9922\n",
              "9   RandomForest    0.9811           0.9810        0.9811    0.9811\n",
              "10  DecisionTree    0.9533           0.9534        0.9532    0.9532\n",
              "11           KNN    0.8042           0.8575        0.8057    0.8079"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== Performance table for task: bg_color =====\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision_macro</th>\n",
              "      <th>recall_macro</th>\n",
              "      <th>f1_macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.9908</td>\n",
              "      <td>0.9908</td>\n",
              "      <td>0.9909</td>\n",
              "      <td>0.9908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RandomForest</td>\n",
              "      <td>0.9672</td>\n",
              "      <td>0.9672</td>\n",
              "      <td>0.9673</td>\n",
              "      <td>0.9673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>KNN</td>\n",
              "      <td>0.9638</td>\n",
              "      <td>0.9640</td>\n",
              "      <td>0.9638</td>\n",
              "      <td>0.9638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DecisionTree</td>\n",
              "      <td>0.9468</td>\n",
              "      <td>0.9468</td>\n",
              "      <td>0.9470</td>\n",
              "      <td>0.9467</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          model  accuracy  precision_macro  recall_macro  f1_macro\n",
              "0       XGBoost    0.9908           0.9908        0.9909    0.9908\n",
              "1  RandomForest    0.9672           0.9672        0.9673    0.9673\n",
              "2           KNN    0.9638           0.9640        0.9638    0.9638\n",
              "3  DecisionTree    0.9468           0.9468        0.9470    0.9467"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ------------------------------------------------------------\n",
        "# [Cell 4] Task별 모델 성능 표 생성\n",
        "#   - 각 Task에 대해 모델 성능을 보기 좋게 정리\n",
        "#   - macro F1 기준 내림차순 정렬\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "tasks = [\"digit\", \"fg_color\", \"bg_color\"]\n",
        "\n",
        "task_tables = {}  # 나중에 보고서/PPT에 쓸 수 있도록 저장\n",
        "\n",
        "for task in tasks:\n",
        "    df_task = summary_df[summary_df[\"task\"] == task].copy()\n",
        "    if df_task.empty:\n",
        "        print(f\"[WARN] No rows for task={task} in summary.\")\n",
        "        continue\n",
        "\n",
        "    # F1 기준 상위 모델부터 정렬\n",
        "    df_task = df_task.sort_values(by=\"f1_macro\", ascending=False)\n",
        "\n",
        "    # 보기 좋은 컬럼 순서로 정리\n",
        "    df_task = df_task[[\n",
        "        \"model\",\n",
        "        \"accuracy\",\n",
        "        \"precision_macro\",\n",
        "        \"recall_macro\",\n",
        "        \"f1_macro\",\n",
        "    ]]\n",
        "\n",
        "    # 소수점 자리 보기 좋게 제한\n",
        "    df_task = df_task.round(4)\n",
        "\n",
        "    task_tables[task] = df_task\n",
        "\n",
        "    print(f\"\\n===== Performance table for task: {task} =====\")\n",
        "    display(df_task)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "883903ac",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[OK] Best models per task:\n",
            "  - digit    : XGBoost (F1=0.9364, Acc=0.9368)\n",
            "  - fg_color : XGBoost (F1=0.9922, Acc=0.9922)\n",
            "  - bg_color : XGBoost (F1=0.9908, Acc=0.9908)\n"
          ]
        }
      ],
      "source": [
        "# ------------------------------------------------------------\n",
        "# [Cell 5] Task별 Best Model 선정\n",
        "#   - macro F1 기준으로 최고 성능 모델 선택\n",
        "#   - 보고서에 바로 쓸 수 있는 dict 생성\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "best_models = {}\n",
        "\n",
        "for task in tasks:\n",
        "    df_task = task_tables.get(task, None)\n",
        "    if df_task is None or df_task.empty:\n",
        "        continue\n",
        "\n",
        "    # F1이 가장 높은 모델 1개 선택\n",
        "    best_row = df_task.sort_values(by=\"f1_macro\", ascending=False).iloc[0]\n",
        "    best_models[task] = {\n",
        "        \"model\": best_row[\"model\"],\n",
        "        \"f1_macro\": float(best_row[\"f1_macro\"]),\n",
        "        \"accuracy\": float(best_row[\"accuracy\"]),\n",
        "    }\n",
        "\n",
        "print(\"\\n[OK] Best models per task:\")\n",
        "for task, info in best_models.items():\n",
        "    print(f\"  - {task:9s}: {info['model']} \"\n",
        "          f\"(F1={info['f1_macro']:.4f}, Acc={info['accuracy']:.4f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0504c085",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[OK] Saved F1 bar chart for digit → /Users/jaehun_jung/colored-mnist-classification/results/figures/bar_f1_digit.png\n",
            "[OK] Saved F1 bar chart for fg_color → /Users/jaehun_jung/colored-mnist-classification/results/figures/bar_f1_fg_color.png\n",
            "[OK] Saved F1 bar chart for bg_color → /Users/jaehun_jung/colored-mnist-classification/results/figures/bar_f1_bg_color.png\n"
          ]
        }
      ],
      "source": [
        "# ------------------------------------------------------------\n",
        "# [Cell 6] 성능 비교 시각화 (막대 그래프)\n",
        "#   - 각 Task별로 모델별 F1-score 비교 바차트 생성\n",
        "#   - 발표용/보고서용 Figure 자동 생성\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "os.makedirs(FIGURES_DIR, exist_ok=True)\n",
        "\n",
        "for task in tasks:\n",
        "    df_task = task_tables.get(task, None)\n",
        "    if df_task is None or df_task.empty:\n",
        "        continue\n",
        "\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.barplot(\n",
        "        data=df_task,\n",
        "        x=\"model\",\n",
        "        y=\"f1_macro\",\n",
        "    )\n",
        "    plt.title(f\"Macro F1 by model - {task}\")\n",
        "    plt.ylim(0, 1.0)\n",
        "    plt.ylabel(\"Macro F1\")\n",
        "    plt.xlabel(\"Model\")\n",
        "    plt.tight_layout()\n",
        "\n",
        "    out_path = os.path.join(FIGURES_DIR, f\"bar_f1_{task}.png\")\n",
        "    plt.savefig(out_path, dpi=200)\n",
        "    plt.close()\n",
        "    print(f\"[OK] Saved F1 bar chart for {task} → {out_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3cd74fe5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------------------------------------------------------\n",
        "# [Cell 7] 분석 문단 자동 생성 함수\n",
        "#   - \"결과 → 원인 → 의미 → 결론\" 구조로 서술형 텍스트 생성\n",
        "#   - 출력 텍스트를 그대로 보고서/노션에 복사해서 사용 가능\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "def generate_task_analysis(task_name: str, table: pd.DataFrame, best_info: dict) -> str:\n",
        "    \"\"\"\n",
        "    각 Task에 대해:\n",
        "      - 어떤 모델이 제일 잘했는지\n",
        "      - 다른 모델과의 격차는 어떤지\n",
        "      - 왜 그런 결과가 나왔을지 (구조적 이유)\n",
        "      - 이 결과가 갖는 의미와 결론\n",
        "    을 하나의 서술형 블록으로 생성.\n",
        "    \"\"\"\n",
        "\n",
        "    # 안전 처리\n",
        "    if table is None or table.empty or best_info is None:\n",
        "        return f\"[{task_name}] No sufficient data to analyze.\\n\"\n",
        "\n",
        "    # Best model 정보\n",
        "    best_model = best_info[\"model\"]\n",
        "    best_f1 = best_info[\"f1_macro\"]\n",
        "\n",
        "    # 비교용: 나머지 모델 평균 F1\n",
        "    others = table[table[\"model\"] != best_model]\n",
        "    if not others.empty:\n",
        "        others_mean_f1 = others[\"f1_macro\"].mean()\n",
        "        gap = best_f1 - others_mean_f1\n",
        "    else:\n",
        "        others_mean_f1 = None\n",
        "        gap = None\n",
        "\n",
        "    # Task별 도메인 설명\n",
        "    if task_name == \"digit\":\n",
        "        task_desc = \"10-class digit classification (0-9)\"\n",
        "        difficulty = \"숫자 형태 정보가 뚜렷하여 비교적 안정적인 분류가 가능한 Task\"\n",
        "    elif task_name == \"fg_color\":\n",
        "        task_desc = \"7-class foreground color classification\"\n",
        "        difficulty = \"전경 색상만 구분해야 하며, 배경/노이즈 영향으로 난도가 상승하는 Task\"\n",
        "    elif task_name == \"bg_color\":\n",
        "        task_desc = \"7-class background color classification\"\n",
        "        difficulty = \"배경 색상만 반영되어야 하며, 전경과의 대비에 따라 혼동이 발생할 수 있는 Task\"\n",
        "    else:\n",
        "        task_desc = task_name\n",
        "        difficulty = \"\"\n",
        "\n",
        "    # 결과 파트\n",
        "    lines = []\n",
        "    lines.append(f\"[Task 설명] {task_desc}\")\n",
        "    if difficulty:\n",
        "        lines.append(f\"[난이도 요약] {difficulty}\")\n",
        "\n",
        "    lines.append(f\"[결과] 이 Task에서 가장 높은 성능을 기록한 모델은 **{best_model}** 이며,\"\n",
        "                 f\" macro F1 기준 **{best_f1:.4f}** 수준이다.\")\n",
        "\n",
        "    if others_mean_f1 is not None:\n",
        "        lines.append(\n",
        "            f\"[비교] 나머지 모델들의 평균 F1은 약 **{others_mean_f1:.4f}** 수준으로,\"\n",
        "            f\" 최고 성능 모델과의 격차는 약 **{(gap):.4f}** 포인트이다.\"\n",
        "        )\n",
        "\n",
        "    # 원인 파트 (모델 특성에 따른 합리적 설명)\n",
        "    if best_model in [\"RandomForest\", \"XGBoost\"]:\n",
        "        lines.append(\n",
        "            \"[원인] 트리 기반 앙상블 모델은 픽셀 단위의 비선형 패턴과 \"\n",
        "            \"색상 조합 정보를 동시에 학습할 수 있어, \"\n",
        "            \"단순 거리 기반(KNN)이나 단일 트리(DecisionTree)에 비해 \"\n",
        "            \"복잡한 결정 경계를 더 잘 표현한다.\"\n",
        "        )\n",
        "    elif best_model == \"KNN\":\n",
        "        lines.append(\n",
        "            \"[원인] KNN은 표준화된 feature 공간에서 국소적인 거리 정보를 활용하기 때문에, \"\n",
        "            \"데이터 분포가 비교적 균일하고 클래스 간 경계가 단순한 경우에 유리하다.\"\n",
        "        )\n",
        "    elif best_model == \"DecisionTree\":\n",
        "        lines.append(\n",
        "            \"[원인] 단일 트리는 해석력은 높지만 일반적으로 앙상블보다 성능이 낮은 편이다. \"\n",
        "            \"만약 본 Task에서 DecisionTree가 높게 나온 경우, \"\n",
        "            \"데이터 패턴이 비교적 단순하거나 깊이 제약이 잘 맞춰진 결과로 해석할 수 있다.\"\n",
        "        )\n",
        "\n",
        "    # 의미 파트\n",
        "    lines.append(\n",
        "        \"[의미] 본 결과는 모델 구조가 색상·형태 정보를 어떻게 활용하는지에 따라 \"\n",
        "        \"성능 차이가 뚜렷하게 발생함을 보여준다. \"\n",
        "        \"특히 앙상블/부스팅 계열 모델은 feature 간 상호작용까지 고려할 수 있기 때문에 \"\n",
        "        \"Colored MNIST와 같은 복합 특성 데이터에서 우위를 가진다.\"\n",
        "    )\n",
        "\n",
        "    # 결론 파트\n",
        "    lines.append(\n",
        "        \"[결론] 최종적으로 이 Task에서는 \"\n",
        "        f\"**{best_model}** 을 기준 모델로 채택하고, \"\n",
        "        \"하이퍼파라미터 튜닝 및 추가적인 전처리 개선을 통해 성능을 보강하는 전략이 타당하다.\"\n",
        "    )\n",
        "\n",
        "    return \"\\n\".join(lines) + \"\\n\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c71ebe86",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================== Analysis: digit ====================\n",
            "[Task 설명] 10-class digit classification (0-9)\n",
            "[난이도 요약] 숫자 형태 정보가 뚜렷하여 비교적 안정적인 분류가 가능한 Task\n",
            "[결과] 이 Task에서 가장 높은 성능을 기록한 모델은 **XGBoost** 이며, macro F1 기준 **0.9364** 수준이다.\n",
            "[비교] 나머지 모델들의 평균 F1은 약 **0.7565** 수준으로, 최고 성능 모델과의 격차는 약 **0.1799** 포인트이다.\n",
            "[원인] 트리 기반 앙상블 모델은 픽셀 단위의 비선형 패턴과 색상 조합 정보를 동시에 학습할 수 있어, 단순 거리 기반(KNN)이나 단일 트리(DecisionTree)에 비해 복잡한 결정 경계를 더 잘 표현한다.\n",
            "[의미] 본 결과는 모델 구조가 색상·형태 정보를 어떻게 활용하는지에 따라 성능 차이가 뚜렷하게 발생함을 보여준다. 특히 앙상블/부스팅 계열 모델은 feature 간 상호작용까지 고려할 수 있기 때문에 Colored MNIST와 같은 복합 특성 데이터에서 우위를 가진다.\n",
            "[결론] 최종적으로 이 Task에서는 **XGBoost** 을 기준 모델로 채택하고, 하이퍼파라미터 튜닝 및 추가적인 전처리 개선을 통해 성능을 보강하는 전략이 타당하다.\n",
            "\n",
            "\n",
            "==================== Analysis: fg_color ====================\n",
            "[Task 설명] 7-class foreground color classification\n",
            "[난이도 요약] 전경 색상만 구분해야 하며, 배경/노이즈 영향으로 난도가 상승하는 Task\n",
            "[결과] 이 Task에서 가장 높은 성능을 기록한 모델은 **XGBoost** 이며, macro F1 기준 **0.9922** 수준이다.\n",
            "[비교] 나머지 모델들의 평균 F1은 약 **0.9141** 수준으로, 최고 성능 모델과의 격차는 약 **0.0781** 포인트이다.\n",
            "[원인] 트리 기반 앙상블 모델은 픽셀 단위의 비선형 패턴과 색상 조합 정보를 동시에 학습할 수 있어, 단순 거리 기반(KNN)이나 단일 트리(DecisionTree)에 비해 복잡한 결정 경계를 더 잘 표현한다.\n",
            "[의미] 본 결과는 모델 구조가 색상·형태 정보를 어떻게 활용하는지에 따라 성능 차이가 뚜렷하게 발생함을 보여준다. 특히 앙상블/부스팅 계열 모델은 feature 간 상호작용까지 고려할 수 있기 때문에 Colored MNIST와 같은 복합 특성 데이터에서 우위를 가진다.\n",
            "[결론] 최종적으로 이 Task에서는 **XGBoost** 을 기준 모델로 채택하고, 하이퍼파라미터 튜닝 및 추가적인 전처리 개선을 통해 성능을 보강하는 전략이 타당하다.\n",
            "\n",
            "\n",
            "==================== Analysis: bg_color ====================\n",
            "[Task 설명] 7-class background color classification\n",
            "[난이도 요약] 배경 색상만 반영되어야 하며, 전경과의 대비에 따라 혼동이 발생할 수 있는 Task\n",
            "[결과] 이 Task에서 가장 높은 성능을 기록한 모델은 **XGBoost** 이며, macro F1 기준 **0.9908** 수준이다.\n",
            "[비교] 나머지 모델들의 평균 F1은 약 **0.9593** 수준으로, 최고 성능 모델과의 격차는 약 **0.0315** 포인트이다.\n",
            "[원인] 트리 기반 앙상블 모델은 픽셀 단위의 비선형 패턴과 색상 조합 정보를 동시에 학습할 수 있어, 단순 거리 기반(KNN)이나 단일 트리(DecisionTree)에 비해 복잡한 결정 경계를 더 잘 표현한다.\n",
            "[의미] 본 결과는 모델 구조가 색상·형태 정보를 어떻게 활용하는지에 따라 성능 차이가 뚜렷하게 발생함을 보여준다. 특히 앙상블/부스팅 계열 모델은 feature 간 상호작용까지 고려할 수 있기 때문에 Colored MNIST와 같은 복합 특성 데이터에서 우위를 가진다.\n",
            "[결론] 최종적으로 이 Task에서는 **XGBoost** 을 기준 모델로 채택하고, 하이퍼파라미터 튜닝 및 추가적인 전처리 개선을 통해 성능을 보강하는 전략이 타당하다.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ------------------------------------------------------------\n",
        "# [Cell 8] Task별 분석 문단 생성 및 표시\n",
        "#   - 노트북 출력 내용을 그대로 보고서/노션에 복사해서 사용 가능\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "analysis_blocks = {}\n",
        "\n",
        "for task in tasks:\n",
        "    table = task_tables.get(task, None)\n",
        "    best_info = best_models.get(task, None)\n",
        "    block = generate_task_analysis(task, table, best_info)\n",
        "    analysis_blocks[task] = block\n",
        "\n",
        "    print(f\"\\n==================== Analysis: {task} ====================\")\n",
        "    print(block)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c96a82be",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================== Overall Summary ====================\n",
            "[종합 결과 요약]\n",
            "- 세 Task 중 다수에서 최상위 F1을 기록한 모델은 **XGBoost** 이며, Colored MNIST 환경에서 가장 일관된 성능을 보였다.\n",
            "- Digit Task는 전통적인 숫자 인식 문제로 상대적으로 높은 정확도를 보였으며, Color 관련 Task(fg_color, bg_color)는 색상 조합과 대비에 따라 난이도가 상승하는 양상이 확인되었다.\n",
            "- 트리 기반 앙상블(RandomForest, XGBoost)은 색상과 형태가 동시에 존재하는 입력에서 강인한 성능을 보였고, Feature Importance 시각화를 통해 모델이 실제로 숫자 영역 및 색상 채널에 집중하고 있음을 확인할 수 있다.\n",
            "- KNN은 단순 baseline으로서 의미는 있으나, 고차원 feature 공간에서의 거리 기반 한계로 인해 부스팅/앙상블 모델 대비 일관적으로 낮은 성능을 보이는 경향을 확인하였다.\n",
            "- 전처리 과정에서의 표준화 적용, FG/BG 색상 라벨 정합성, 과도하지 않은 augmentation 전략이 전체 실험의 안정성을 높이는 핵심 요소로 작용하였다.\n",
            "[최종 결론] 본 프로젝트에서는 트리 기반 앙상블과 부스팅(XGBoost)을 중심 모델로 채택하고, Colored MNIST와 유사한 구조의 데이터에서 전통적 ML 기법만으로도 충분히 경쟁력 있는 성능과 해석 가능성을 확보할 수 있음을 보였다.\n"
          ]
        }
      ],
      "source": [
        "# ------------------------------------------------------------\n",
        "# [Cell 9] 전체 프로젝트 요약 문단 생성\n",
        "#   - 3개 Task 결과를 종합한 high-level 결론\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "def generate_overall_summary(best_models_dict):\n",
        "    \"\"\"\n",
        "    프로젝트 전체 관점에서:\n",
        "      - 어떤 모델이 전반적으로 우수했는지\n",
        "      - Digit / Color 태스크 간 난이도 차이\n",
        "      - 전처리 & 모델링 전략이 유효했는지\n",
        "    를 요약하는 문단 생성.\n",
        "    \"\"\"\n",
        "\n",
        "    # 어떤 모델이 몇 번 Best인지 카운트\n",
        "    model_counts = {}\n",
        "    for info in best_models_dict.values():\n",
        "        m = info[\"model\"]\n",
        "        model_counts[m] = model_counts.get(m, 0) + 1\n",
        "\n",
        "    # 가장 많이 선택된 모델\n",
        "    if model_counts:\n",
        "        overall_best = max(model_counts.items(), key=lambda x: x[1])[0]\n",
        "    else:\n",
        "        overall_best = None\n",
        "\n",
        "    lines = []\n",
        "\n",
        "    lines.append(\"[종합 결과 요약]\")\n",
        "    if overall_best:\n",
        "        lines.append(\n",
        "            f\"- 세 Task 중 다수에서 최상위 F1을 기록한 모델은 **{overall_best}** 이며,\"\n",
        "            \" Colored MNIST 환경에서 가장 일관된 성능을 보였다.\"\n",
        "        )\n",
        "\n",
        "    lines.append(\n",
        "        \"- Digit Task는 전통적인 숫자 인식 문제로 상대적으로 높은 정확도를 보였으며, \"\n",
        "        \"Color 관련 Task(fg_color, bg_color)는 색상 조합과 대비에 따라 난이도가 상승하는 양상이 확인되었다.\"\n",
        "    )\n",
        "\n",
        "    lines.append(\n",
        "        \"- 트리 기반 앙상블(RandomForest, XGBoost)은 \"\n",
        "        \"색상과 형태가 동시에 존재하는 입력에서 강인한 성능을 보였고, \"\n",
        "        \"Feature Importance 시각화를 통해 모델이 실제로 숫자 영역 및 색상 채널에 집중하고 있음을 확인할 수 있다.\"\n",
        "    )\n",
        "\n",
        "    lines.append(\n",
        "        \"- KNN은 단순 baseline으로서 의미는 있으나, \"\n",
        "        \"고차원 feature 공간에서의 거리 기반 한계로 인해 \"\n",
        "        \"부스팅/앙상블 모델 대비 일관적으로 낮은 성능을 보이는 경향을 확인하였다.\"\n",
        "    )\n",
        "\n",
        "    lines.append(\n",
        "        \"- 전처리 과정에서의 표준화 적용, FG/BG 색상 라벨 정합성, \"\n",
        "        \"과도하지 않은 augmentation 전략이 전체 실험의 안정성을 높이는 핵심 요소로 작용하였다.\"\n",
        "    )\n",
        "\n",
        "    lines.append(\n",
        "        \"[최종 결론] 본 프로젝트에서는 \"\n",
        "        \"트리 기반 앙상블과 부스팅(XGBoost)을 중심 모델로 채택하고, \"\n",
        "        \"Colored MNIST와 유사한 구조의 데이터에서 전통적 ML 기법만으로도 \"\n",
        "        \"충분히 경쟁력 있는 성능과 해석 가능성을 확보할 수 있음을 보였다.\"\n",
        "    )\n",
        "\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "\n",
        "overall_summary = generate_overall_summary(best_models)\n",
        "\n",
        "print(\"\\n==================== Overall Summary ====================\")\n",
        "print(overall_summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4eb2e771",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
